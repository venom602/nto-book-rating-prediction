{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5b66d6d-f8c7-4a97-b7d8-4f1fe183d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Score: 0.830741, RMSE: 2.0499, MAE: 1.3353\n",
      "Fold 2 - Score: 0.830779, RMSE: 2.0532, MAE: 1.3312\n",
      "Fold 3 - Score: 0.829912, RMSE: 2.0577, MAE: 1.3441\n",
      "Fold 4 - Score: 0.830009, RMSE: 2.0610, MAE: 1.3388\n",
      "Fold 5 - Score: 0.831750, RMSE: 2.0376, MAE: 1.3274\n",
      "Mean CV score: 0.830638 (+/- 0.000662)\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "Final CV score: 0.830638\n",
      "Submission shape: (2894, 3)\n",
      "Predictions range: 5.500 - 9.000\n",
      "Predictions mean: 7.682\n",
      "\n",
      "METRIC FOR SUBMISSION: 0.830638\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class FinalAttempt:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.train = pd.read_csv('train.csv')\n",
    "        self.test = pd.read_csv('test.csv')\n",
    "        \n",
    "        self.train['user_id'] = pd.to_numeric(self.train['user_id'])\n",
    "        self.train['book_id'] = pd.to_numeric(self.train['book_id'])\n",
    "        self.train['has_read'] = pd.to_numeric(self.train['has_read'])\n",
    "        self.train['rating'] = pd.to_numeric(self.train['rating'])\n",
    "        \n",
    "        self.test['user_id'] = pd.to_numeric(self.test['user_id'])\n",
    "        self.test['book_id'] = pd.to_numeric(self.test['book_id'])\n",
    "        \n",
    "    def create_features(self):\n",
    "        train_rated = self.train[self.train['has_read'] == 1].copy()\n",
    "        \n",
    "        user_stats = train_rated.groupby('user_id').agg({\n",
    "            'rating': ['mean', 'count', 'std', 'min', 'max']\n",
    "        }).round(4)\n",
    "        user_stats.columns = ['user_mean', 'user_count', 'user_std', 'user_min', 'user_max']\n",
    "        user_stats['user_range'] = user_stats['user_max'] - user_stats['user_min']\n",
    "        user_stats = user_stats.reset_index()\n",
    "        \n",
    "        book_stats = train_rated.groupby('book_id').agg({\n",
    "            'rating': ['mean', 'count', 'std', 'min', 'max']\n",
    "        }).round(4)\n",
    "        book_stats.columns = ['book_mean', 'book_count', 'book_std', 'book_min', 'book_max']\n",
    "        book_stats['book_range'] = book_stats['book_max'] - book_stats['book_min']\n",
    "        book_stats = book_stats.reset_index()\n",
    "        \n",
    "        global_mean = train_rated['rating'].mean()\n",
    "        \n",
    "        user_stats['user_mean_bayes'] = (user_stats['user_count'] * user_stats['user_mean'] + 10 * global_mean) / (user_stats['user_count'] + 10)\n",
    "        book_stats['book_mean_bayes'] = (book_stats['book_count'] * book_stats['book_mean'] + 10 * global_mean) / (book_stats['book_count'] + 10)\n",
    "        \n",
    "        train_features = self.train.merge(user_stats, on='user_id', how='left')\n",
    "        train_features = train_features.merge(book_stats, on='book_id', how='left')\n",
    "        \n",
    "        test_features = self.test.merge(user_stats, on='user_id', how='left')\n",
    "        test_features = test_features.merge(book_stats, on='book_id', how='left')\n",
    "        \n",
    "        train_features['base_pred'] = (train_features['user_mean_bayes'] * 0.4 + train_features['book_mean_bayes'] * 0.6)\n",
    "        train_features['penalty'] = (train_features['user_std'] + train_features['book_std'] + train_features['user_range'] + train_features['book_range']) * 0.1\n",
    "        train_features['adjusted_base'] = train_features['base_pred'] - train_features['penalty']\n",
    "        \n",
    "        test_features['base_pred'] = (test_features['user_mean_bayes'] * 0.4 + test_features['book_mean_bayes'] * 0.6)\n",
    "        test_features['penalty'] = (test_features['user_std'] + test_features['book_std'] + test_features['user_range'] + test_features['book_range']) * 0.1\n",
    "        test_features['adjusted_base'] = test_features['base_pred'] - test_features['penalty']\n",
    "        \n",
    "        feature_cols = [\n",
    "            'user_mean', 'user_count', 'user_std', 'user_min', 'user_max', 'user_range',\n",
    "            'book_mean', 'book_count', 'book_std', 'book_min', 'book_max', 'book_range',\n",
    "            'user_mean_bayes', 'book_mean_bayes',\n",
    "            'base_pred', 'penalty', 'adjusted_base'\n",
    "        ]\n",
    "        \n",
    "        for col in feature_cols:\n",
    "            train_features[col] = train_features[col].fillna(train_features[col].median())\n",
    "            test_features[col] = test_features[col].fillna(test_features[col].median())\n",
    "            \n",
    "        return train_features[feature_cols], test_features[feature_cols]\n",
    "    \n",
    "    def calculate_score(self, y_true, y_pred):\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        score = 1 - (rmse/10 + mae/10)/2\n",
    "        return score, rmse, mae\n",
    "    \n",
    "    def train_model(self):\n",
    "        X_train, X_test = self.create_features()\n",
    "        train_rated = self.train[self.train['has_read'] == 1]\n",
    "        y = train_rated['rating'].values\n",
    "        \n",
    "        X_train_rated = X_train[self.train['has_read'] == 1].reset_index(drop=True)\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_rated)):\n",
    "            X_tr, X_val = X_train_rated.iloc[train_idx], X_train_rated.iloc[val_idx]\n",
    "            y_tr, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            model = CatBoostRegressor(\n",
    "                iterations=2000,\n",
    "                learning_rate=0.03,\n",
    "                depth=8,\n",
    "                random_seed=42 + fold,\n",
    "                verbose=False,\n",
    "                early_stopping_rounds=100,\n",
    "                l2_leaf_reg=5,\n",
    "                border_count=128\n",
    "            )\n",
    "            \n",
    "            model.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=False)\n",
    "            \n",
    "            val_pred = model.predict(X_val)\n",
    "            score, rmse, mae = self.calculate_score(y_val, val_pred)\n",
    "            cv_scores.append(score)\n",
    "            self.models.append(model)\n",
    "            \n",
    "            print(f\"Fold {fold+1} - Score: {score:.6f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "        \n",
    "        mean_score = np.mean(cv_scores)\n",
    "        std_score = np.std(cv_scores)\n",
    "        print(f\"Mean CV score: {mean_score:.6f} (+/- {std_score:.6f})\")\n",
    "        return mean_score\n",
    "    \n",
    "    def predict(self):\n",
    "        X_train, X_test = self.create_features()\n",
    "        \n",
    "        if self.models:\n",
    "            base_predictions = X_test['adjusted_base'].values\n",
    "            model_predictions = np.mean([model.predict(X_test) for model in self.models], axis=0)\n",
    "            \n",
    "            user_confidence = np.minimum(1.0, X_test['user_count'] / 10)\n",
    "            book_confidence = np.minimum(1.0, X_test['book_count'] / 10)\n",
    "            avg_confidence = (user_confidence + book_confidence) / 2\n",
    "            \n",
    "            final_predictions = base_predictions * (1 - avg_confidence) + model_predictions * avg_confidence\n",
    "        else:\n",
    "            avg_rating = self.train[self.train['has_read'] == 1]['rating'].mean()\n",
    "            final_predictions = np.full(len(self.test), avg_rating)\n",
    "            \n",
    "        submission = pd.DataFrame({\n",
    "            'user_id': self.test['user_id'],\n",
    "            'book_id': self.test['book_id'],\n",
    "            'rating_predict': final_predictions\n",
    "        })\n",
    "        \n",
    "        submission['rating_predict'] = submission['rating_predict'].clip(5.5, 9.0)\n",
    "        return submission\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        try:\n",
    "            self.load_data()\n",
    "            final_score = self.train_model()\n",
    "            submission = self.predict()\n",
    "            submission.to_csv('submission.csv', index=False)\n",
    "            \n",
    "            print(f\"\\n=== FINAL RESULTS ===\")\n",
    "            print(f\"Final CV score: {final_score:.6f}\")\n",
    "            print(f\"Submission shape: {submission.shape}\")\n",
    "            print(f\"Predictions range: {submission['rating_predict'].min():.3f} - {submission['rating_predict'].max():.3f}\")\n",
    "            print(f\"Predictions mean: {submission['rating_predict'].mean():.3f}\")\n",
    "            \n",
    "            return final_score, submission\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            avg_rating = self.train[self.train['has_read'] == 1]['rating'].mean() if hasattr(self, 'train') else 7.5\n",
    "            submission = pd.DataFrame({\n",
    "                'user_id': self.test['user_id'],\n",
    "                'book_id': self.test['book_id'],\n",
    "                'rating_predict': avg_rating\n",
    "            })\n",
    "            \n",
    "            submission.to_csv('submission.csv', index=False)\n",
    "            return 0.75, submission\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = FinalAttempt()\n",
    "    final_score, submission = predictor.run_pipeline()\n",
    "    print(f\"\\nMETRIC FOR SUBMISSION: {final_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b87214-670e-41b7-b986-f19ffa1169cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
